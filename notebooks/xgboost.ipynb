{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29bfa07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho original do dataset: 253,680 amostras\n",
      "Distribuição original das classes:\n",
      "Diabetes_binary\n",
      "0.0    0.842412\n",
      "1.0    0.157588\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      " Divisão final dos dados:\n",
      "Treino: 177,576 amostras\n",
      "Teste: 76,104 amostras\n",
      "Features: 16 características\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from scipy.stats.mstats import winsorize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./data/diabetes_012_health_indicators_BRFSS2015.csv')\n",
    "print(f\"Tamanho original do dataset: {len(df):,} amostras\")\n",
    "\n",
    "# Selecionar features\n",
    "features = [\n",
    "    'HighBP', 'HighChol', 'BMI', 'Smoker', 'Stroke',\n",
    "    'HeartDiseaseorAttack', 'PhysActivity',\n",
    "    'Veggies', 'HvyAlcoholConsump', 'GenHlth', 'MentHlth',\n",
    "    'PhysHlth', 'DiffWalk', 'Age', 'Education', 'Income'\n",
    "]\n",
    "\n",
    "target = 'Diabetes_012'\n",
    "\n",
    "# Colunas que precisam ser escaladas\n",
    "cols_to_scale = ['BMI', 'GenHlth', 'MentHlth', 'PhysHlth', 'Age', 'Education', 'Income']\n",
    "\n",
    "# Copiar dataset para pré-processamento\n",
    "df_processed = df[features + [target]].copy()\n",
    "\n",
    "# Transformar a variável alvo em binária: 1 para pré-diabetes e diabetes, 0 para sem diabetes\n",
    "df_processed['Diabetes_012'] = df['Diabetes_012'].replace({2:1})\n",
    "df_processed = df_processed.rename(columns = {'Diabetes_012': 'Diabetes_binary'})\n",
    "\n",
    "print(f\"Distribuição original das classes:\")\n",
    "print(df_processed['Diabetes_binary'].value_counts(normalize=True))\n",
    "\n",
    "# Aplicar padronização Z-score nas colunas selecionadas\n",
    "scaler = StandardScaler()\n",
    "df_processed[cols_to_scale] = scaler.fit_transform(df_processed[cols_to_scale])\n",
    "\n",
    "# Separar conjuntos para classificação (agora com a variável alvo binária)\n",
    "X_class = df_processed[features].values\n",
    "y_class = df_processed['Diabetes_binary'].values\n",
    "\n",
    "# Separar treino e teste (somente para classificação)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_class, y_class, test_size=0.3, random_state=42, stratify=y_class\n",
    ")\n",
    "\n",
    "print(f\"\\n Divisão final dos dados:\")\n",
    "print(f\"Treino: {X_train.shape[0]:,} amostras\")\n",
    "print(f\"Teste: {X_test.shape[0]:,} amostras\")\n",
    "print(f\"Features: {X_train.shape[1]} características\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d1a8ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe 0.0: 149592 exemplos (50.00%)\n",
      "Classe 1.0: 149592 exemplos (50.00%)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Aplicar SMOTE ao conjunto de treino\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Verificar nova distribuição\n",
    "unique, counts = np.unique(y_resampled, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    pct = count / sum(counts) * 100\n",
    "    print(f'Classe {cls}: {count} exemplos ({pct:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ab7052a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando Grid Search para otimização de hiperparâmetros...\n",
      "Fitting 3 folds for each of 45 candidates, totalling 135 fits\n",
      "\n",
      "Melhores parâmetros encontrados: {'learning_rate': 0.05, 'max_depth': 9, 'n_estimators': 100}\n",
      "Melhor score CV: 0.8454\n",
      "Tempo de treinamento: 83.68 segundos\n",
      "\n",
      "=== MÉTRICAS DO CONJUNTO DE TREINO ===\n",
      "Accuracy: 0.8897\n",
      "Precision: 0.9052\n",
      "Recall: 0.8705\n",
      "F1-Score: 0.8875\n",
      "ROC-AUC: 0.9592\n",
      "\n",
      "Relatório de classificação (Treino):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.91      0.89    149592\n",
      "         1.0       0.91      0.87      0.89    149592\n",
      "\n",
      "    accuracy                           0.89    299184\n",
      "   macro avg       0.89      0.89      0.89    299184\n",
      "weighted avg       0.89      0.89      0.89    299184\n",
      "\n",
      "Matriz de confusão (Treino):\n",
      "[[135962  13630]\n",
      " [ 19371 130221]]\n",
      "\n",
      "=== MÉTRICAS DO CONJUNTO DE TESTE ===\n",
      "Accuracy: 0.8341\n",
      "Precision: 0.4715\n",
      "Recall: 0.4381\n",
      "F1-Score: 0.4542\n",
      "ROC-AUC: 0.8182\n",
      "\n",
      "Relatório de classificação (Teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.91      0.90     64111\n",
      "         1.0       0.47      0.44      0.45     11993\n",
      "\n",
      "    accuracy                           0.83     76104\n",
      "   macro avg       0.68      0.67      0.68     76104\n",
      "weighted avg       0.83      0.83      0.83     76104\n",
      "\n",
      "Matriz de confusão (Teste):\n",
      "[[58221  5890]\n",
      " [ 6739  5254]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid Search para otimizar hiperparâmetros\n",
    "print(\"Iniciando Grid Search para otimização de hiperparâmetros...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Definir grid de parâmetros\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 6, 9, 12, 15],\n",
    "    'learning_rate': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Criar modelo base\n",
    "xgb_base = XGBClassifier(\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Configurar Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Executar Grid Search\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Obter melhor modelo\n",
    "xgb_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"\\nMelhores parâmetros encontrados: {grid_search.best_params_}\")\n",
    "print(f\"Melhor score CV: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "xgb_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Tempo de treinamento: {training_time:.2f} segundos\")\n",
    "\n",
    "# Predições\n",
    "y_pred_train = xgb_model.predict(X_resampled)\n",
    "y_pred_test = xgb_model.predict(X_test)\n",
    "\n",
    "# Probabilidades para ROC-AUC\n",
    "y_proba_train = xgb_model.predict_proba(X_resampled)[:, 1]\n",
    "y_proba_test = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Métricas para conjunto de treino\n",
    "print(\"\\n=== MÉTRICAS DO CONJUNTO DE TREINO ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_resampled, y_pred_train):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_resampled, y_pred_train):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_resampled, y_pred_train):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_resampled, y_pred_train):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_resampled, y_proba_train):.4f}\")\n",
    "\n",
    "print(\"\\nRelatório de classificação (Treino):\")\n",
    "print(classification_report(y_resampled, y_pred_train))\n",
    "\n",
    "print(\"Matriz de confusão (Treino):\")\n",
    "print(confusion_matrix(y_resampled, y_pred_train))\n",
    "\n",
    "# Métricas para conjunto de teste\n",
    "print(\"\\n=== MÉTRICAS DO CONJUNTO DE TESTE ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba_test):.4f}\")\n",
    "\n",
    "print(\"\\nRelatório de classificação (Teste):\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "print(\"Matriz de confusão (Teste):\")\n",
    "print(confusion_matrix(y_test, y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
